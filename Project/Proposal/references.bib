% ============================================
% FOUNDATIONAL PAPERS (4)
% ============================================

@book{sutton2018reinforcement,
  title     = {Reinforcement Learning: An Introduction},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  edition   = {2nd},
  year      = {2018},
  publisher = {MIT Press},
  address   = {Cambridge, MA}
}

@article{mnih2015human,
  title     = {Human-level control through deep reinforcement learning},
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal   = {Nature},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  year      = {2015},
  publisher = {Nature Publishing Group}
}

@article{schulman2017proximal,
  title   = {Proximal policy optimization algorithms},
  author  = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal = {arXiv preprint arXiv:1707.06347},
  year    = {2017}
}

@inproceedings{haarnoja2018soft,
  title     = {Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author    = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = {International Conference on Machine Learning},
  pages     = {1861--1870},
  year      = {2018},
  organization = {PMLR}
}

% ============================================
% RECENT PAPERS 2023-2026 (8)
% ============================================

% Minesweeper - most recent academic paper
@article{phan2025training,
  title     = {Training a Minesweeper Agent Using a Convolutional Neural Network},
  author    = {Phan, Alexander V. and Nguyen, Thi Thanh Huyen},
  journal   = {Applied Sciences},
  volume    = {15},
  number    = {5},
  pages     = {2490},
  year      = {2025},
  publisher = {MDPI}
}

% DQN improvements - AAMAS 2025
@inproceedings{zhang2025betadqn,
  title     = {$\beta$-{DQN}: Improving Deep {Q}-Learning By Evolving the Behavior},
  author    = {Zhang, Hongming and Chen, Chao and Xu, Zhiyu and Yu, Liheng and Yu, Yali and others},
  booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
  pages     = {2317--2325},
  year      = {2025}
}

% Sparse rewards - AAAI 2024
@inproceedings{chen2024stas,
  title     = {{STAS}: Spatial-temporal return decomposition for solving sparse rewards problems in multi-agent reinforcement learning},
  author    = {Chen, Sirui and Zhang, Zhaowei and Yang, Yaodong and Du, Yali},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {38},
  pages     = {17337--17345},
  year      = {2024}
}

% Sparse rewards - ICML 2023
@inproceedings{liu2023lazy,
  title     = {Lazy Agents: A New Perspective on Solving Sparse Reward Problem in Multi-agent Reinforcement Learning},
  author    = {Liu, Boyin and Pu, Zhiqiang and Pan, Yi and Yi, Jianqiang and Liang, Yanyan and Zhang, Du},
  booktitle = {International Conference on Machine Learning},
  pages     = {21937--21950},
  year      = {2023},
  organization = {PMLR}
}

% DQN improvements - 2024
@article{han2024elastic,
  title     = {Elastic step {DQN}: A novel multi-step algorithm to alleviate overestimation in Deep {Q}-Networks},
  author    = {Han, Shiyu and Zhang, Zishu and Chen, Wuchen and Li, Yanchen},
  journal   = {Neurocomputing},
  volume    = {567},
  pages     = {127036},
  year      = {2024},
  publisher = {Elsevier}
}

% Comprehensive RL survey - 2024
@article{murphy2024reinforcement,
  title   = {Reinforcement Learning: An Overview},
  author  = {Murphy, Kevin P.},
  journal = {arXiv preprint arXiv:2412.05265},
  year    = {2024}
}

% Meta-RL with Minesweeper - 2025
@article{jiang2025metarl,
  title   = {Meta-{RL} Induces Exploration in Language Agents},
  author  = {Jiang, Yulun and Zhang, Haonan and Chen, Qingpeng and Xiao, Zhimin},
  journal = {arXiv preprint arXiv:2512.16848},
  year    = {2025}
}

% Curriculum learning - recent
@inproceedings{parker2022syllabus,
  title     = {Syllabus: Portable Curricula for Reinforcement Learning Agents},
  author    = {Parker-Holder, Jack and Jiang, Minqi and Dennis, Michael and Samvelyan, Mikayel and Foerster, Jakob and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  booktitle = {Reinforcement Learning Conference},
  year      = {2024}
}
